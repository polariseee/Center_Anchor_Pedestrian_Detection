dataset = dict(
    sampling_function='kp_detection',
    batch_size=8,
    hyratio=0.5,
    size_train=(480, 640),
    size_test=(480, 640),
    img_channel_mean=[103.939, 116.779, 123.68],
    rand_color=True,
    lighting=True,
    eig_val=[0.2141788, 0.01817699, 0.00341571],
    eig_vec=[[-0.58752847, -0.69563484, 0.41340352],
             [-0.5832747, 0.00994535, -0.81221408],
             [-0.56089297, 0.71832671, 0.41158938]]
)
train_cfg = dict(
    opt_algo="adam",
    prefetch_size=5,
    max_iter=400000,
    stepsize=350000,
    snapshot=10000,
    sample_module='Caltech',
    chunk_sizes=[8],
    learning_rate=1e-4,
    decay_rate=10,
    display=100,
    pretrain=None,
    cache_ped='data/cache/caltech/train_gt',
    cache_emp='data/cache/caltech/train_nogt',
    work_dir='/home/zhangl/work_dir/CAP/anchor_head')
test_cfg = dict(
    test=None,
    sample_module='Caltech',
    save_dir='/home/zhangl/work_dir/CAP/anchor_head',
    data_dir='/home/zhangl/DATASET/Caltech/Final_Caltech/test',
    nms_algorithm='exp_soft_nms',
    nms_threshold=0.5,
    scores_csp=0.01,
    nms_pre=1000,
    max_per_img=100,
    scores_bbox=0.1)
backbone = dict(
    pretrained='torchvision://resnet50',
    depth=50,
    num_stages=4,
    dilations=(1, 1, 1, 2),
    strides=(1, 2, 2, 1),
    out_indices=(0, 1, 2, 3),
    frozen_stages=0,
    norm_cfg=dict(type='BN', requires_grad=True),
    norm_eval=True,
    style='pytorch')
fpn = dict(
    in_channels=[256, 512, 1024, 2048],
    out_channels=256,
    start_level=1,
    add_extra_convs=True,
    num_outs=4)
bfp = dict(
    in_channels=256,
    num_levels=4,
    refine_level=1,
    refine_type='non_local')
anchor_head = dict(
    num_classes=1,
    in_channels=256,
    stacked_convs=4,
    feat_channels=256,
    anchor_generator=dict(
        octave_base_scale=4,
        scales_per_octave=3,
        ratios=[2.25, 2.5, 2.75, 3.0, 3.25],
        # ratios=[2.75, 3.0, 3.25],
        strides=[8, 16, 16, 32],
        base_sizes=[8, 16, 32, 64]),
    bbox_coder=dict(
        target_means=(.0, .0, .0, .0),
        target_stds=(1.0, 1.0, 1.0, 1.0)),
    focal_loss=dict(
        use_sigmoid=True,
        loss_weight=1.0),
    balanced_l1_loss=dict(
        alpha=0.5,
        gamma=1.5,
        beta=0.11,
        loss_weight=1.0),
    train_cfg=dict(
        assigner=dict(
            pos_iou_thr=0.5,
            neg_iou_thr=0.4,
            min_pos_iou=0,
            ignore_iof_thr=0.5,
            ignore_wrt_candidates=False),
        allowed_border=-1,
        pos_weight=-1,
        debug=False))
